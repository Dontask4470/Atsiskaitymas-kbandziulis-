{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a32b5de1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a32b5de1",
     "kernelId": "34e876a3-e343-4319-a11f-2e832b75e4da"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Conv2D, BatchNormalization, \\\n",
    "                                    Activation, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from IPython.display import YouTubeVideo\n",
    "from PIL import Image\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80e06a7d",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "80e06a7d",
     "kernelId": "34e876a3-e343-4319-a11f-2e832b75e4da"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(path, model):\n",
    "    X, y = pickle.load(gzip.open(path, 'rb'))\n",
    "    y[y != 0] -= 2\n",
    "    X = X / 255.\n",
    "    acc = np.mean(model(X).numpy().argmax(axis=1) == y)\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89d088ad",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "89d088ad",
     "kernelId": "34e876a3-e343-4319-a11f-2e832b75e4da"
    }
   },
   "outputs": [],
   "source": [
    "path = 'flatland_train.data'\n",
    "X, y =pickle.load(gzip.open(path,'rb'))\n",
    "\n",
    "#pre-processing(hope i'm doing this right)\n",
    "y[y != 0] -= 2\n",
    "X = X / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e51968f6",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e51968f6",
     "kernelId": "34e876a3-e343-4319-a11f-2e832b75e4da"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 1868, 4.0: 1761, 3.0: 2137, 1.0: 2853, 0.0: 1381})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b9a06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4d71b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape =(50,50)))\n",
    "model.add(keras.layers.Dense(20,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(5,activation=\"softmax\"))\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f77e5b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0658 - accuracy: 0.5604\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0471 - accuracy: 0.5711\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0296 - accuracy: 0.5848\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0124 - accuracy: 0.5850\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9943 - accuracy: 0.5960\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9763 - accuracy: 0.6035\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9577 - accuracy: 0.6158\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9418 - accuracy: 0.6228\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9234 - accuracy: 0.6349\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9090 - accuracy: 0.6401\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8951 - accuracy: 0.6439\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8789 - accuracy: 0.6569\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8676 - accuracy: 0.6595\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8520 - accuracy: 0.6597\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8397 - accuracy: 0.6672\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8292 - accuracy: 0.6782\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8154 - accuracy: 0.6797\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8058 - accuracy: 0.6840\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7958 - accuracy: 0.6873\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7838 - accuracy: 0.6967\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7767 - accuracy: 0.6962\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7665 - accuracy: 0.6979\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7574 - accuracy: 0.7042\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7501 - accuracy: 0.7074\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7398 - accuracy: 0.7108\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7322 - accuracy: 0.7172\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7244 - accuracy: 0.7165\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7190 - accuracy: 0.7232\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7128 - accuracy: 0.7245\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7050 - accuracy: 0.7301\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6947 - accuracy: 0.7308\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6916 - accuracy: 0.7312\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6852 - accuracy: 0.7359\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.7393\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6718 - accuracy: 0.7407\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6636 - accuracy: 0.7450\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6587 - accuracy: 0.7463\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6542 - accuracy: 0.7463\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6492 - accuracy: 0.7483\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6442 - accuracy: 0.7496\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6399 - accuracy: 0.75 - 1s 3ms/step - loss: 0.6394 - accuracy: 0.7565\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6334 - accuracy: 0.7568\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.7584\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6228 - accuracy: 0.7627\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6181 - accuracy: 0.7635\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6140 - accuracy: 0.7650\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6080 - accuracy: 0.7688\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6041 - accuracy: 0.7699\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5989 - accuracy: 0.7721\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.7754\n"
     ]
    }
   ],
   "source": [
    "for x in range(50):\n",
    "    model.fit(X,y)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88be7af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hope for the best, prepare for the worst,\n",
    "#there was a very quick and shoddy overnight attempt\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d782bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16352cf2",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "16352cf2",
     "kernelId": "34e876a3-e343-4319-a11f-2e832b75e4da"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7813"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('model.h5')\n",
    "evaluate('flatland_train.data', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f7bae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
